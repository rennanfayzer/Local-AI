# Escrita Sincerta LLM - Starter Pro
### Sistema LLM local completo com agentes especializados, RAG vetorial e interface web

![Stack](https://img.shields.io/badge/Stack-Docker-blue?logo=docker)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Platform](https://img.shields.io/badge/Platform-Linux%20|%20Windows-lightgrey)

---

### ğŸ¯ VisÃ£o Geral
Sistema LLM 100% local que implementa o Manifesto **"Escrita Sincerta"** - comunicaÃ§Ã£o direta, tÃ©cnica e honesta. Inclui agentes especializados, memÃ³ria vetorial persistente com `pgvector` e uma interface web intuitiva para interaÃ§Ã£o. O projeto Ã© totalmente containerizado com Docker para garantir reprodutibilidade e facilidade de setup.

### âœ¨ CaracterÃ­sticas Principais
ğŸ”’ **100% Local**: Sem dependÃªncia de APIs externas, garantindo privacidade e controle total.
ğŸ¤– **Agentes Especializados**: Use agentes prÃ©-configurados para tarefas especÃ­ficas.
ğŸ“š **RAG com pgvector**: EnriqueÃ§a o conhecimento do LLM com seus prÃ³prios documentos (PDFs, TXT, MD).
ğŸ’¾ **MemÃ³ria Persistente**: A base vetorial `pgvector` armazena o conhecimento de forma duradoura.
ğŸš€ **ExecuÃ§Ã£o com Docker**: Ambiente padronizado e de fÃ¡cil manutenÃ§Ã£o com `docker-compose`.
ğŸ”§ **Multiplataforma**: Funciona em Windows, Linux e macOS.
ğŸ”€ **Suporte a MÃºltiplos Modelos**: Flexibilidade para alternar entre modelos como `phi3`, `qwen` e outros suportados pelo Ollama.

### ğŸš€ InÃ­cio RÃ¡pido
**1. PrÃ©-requisitos**
- [Docker](https://www.docker.com/products/docker-desktop/) e Docker Compose
- `git` para clonar o repositÃ³rio

**2. InstalaÃ§Ã£o e ExecuÃ§Ã£o**
```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/rennanfayzer/Local-AI.git
cd Local-AI

# 2. Configure o ambiente
# Copie o arquivo de exemplo e ajuste as variÃ¡veis se necessÃ¡rio
cp .env.example .env

# 3. Inicie todos os serviÃ§os com Docker
# Isso irÃ¡ construir as imagens e iniciar os containers
make up

# 4. Baixe os modelos LLM definidos no .env
make pull
```

**3. Acessos**
- ğŸŒ **Interface Web**: [http://localhost:3000](http://localhost:3000) (Porta configurÃ¡vel em `.env`)
- ğŸ”Œ **API**: [http://localhost:8000](http://localhost:8000)
- ğŸ“Š **DocumentaÃ§Ã£o da API**: [http://localhost:8000/docs](http://localhost:8000/docs)

---

### ğŸ—ï¸ Arquitetura
A arquitetura foi desenhada para ser modular e escalÃ¡vel, utilizando Docker para orquestrar os serviÃ§os.

```mermaid
graph TD
    UI[Open WebUI :3000] --> API[FastAPI Orquestradora :8000]
    API --> OLLAMA[Ollama Runtime :11434]
    API --> RAG[Sistema RAG]

    subgraph "Base de Conhecimento"
        RAG --> PG[Postgres + pgvector]
    end

    subgraph "Modelos LLM"
        OLLAMA --> M1[phi3:3.8b]
        OLLAMA --> M2[qwen2.5:7b]
        OLLAMA --> M3[...]
    end

    subgraph "Documentos do UsuÃ¡rio"
        DOCS[data/docs] -- IngestÃ£o --> RAG
    end
```

#### ğŸ§± Componentes
| ServiÃ§o | Responsabilidade |
|---|---|
| **FastAPI** | OrquestraÃ§Ã£o, exposiÃ§Ã£o de agentes, RAG, e endpoints de controle. |
| **Ollama** | Runtime local para os modelos de linguagem (LLMs). |
| **Open WebUI** | Interface de chat estÃ¡tica para interagir com a API. |
| **Postgres + pgvector** | Banco de dados vetorial para o sistema RAG e memÃ³ria persistente. |

---

### ğŸ¤– Agentes Especializados
O sistema conta com agentes que possuem personalidades e especialidades distintas, definidas via *system prompts*.

- **ğŸ§  Reflexivo**
  - **Modelo**: `phi3:3.8b` (otimizado para anÃ¡lise rÃ¡pida).
  - **Especialidades**: AnÃ¡lise de problemas, planejamento estratÃ©gico, decomposiÃ§Ã£o de tarefas e tomada de decisÃµes.
  - **Capacidades**: Ideal para organizar ideias, avaliar riscos e criar planos de aÃ§Ã£o.

- **ğŸ”§ Dev Fullstack**
  - **Modelo**: `qwen2.5:7b` (equilÃ­brio entre velocidade e capacidade).
  - **Especialidades**: Python, JavaScript, APIs, debugging e desenvolvimento geral.
  - **Capacidades**: GeraÃ§Ã£o de cÃ³digo, revisÃ£o, refatoraÃ§Ã£o e testes.

---

### ğŸ“‹ Comandos DisponÃ­veis
A automaÃ§Ã£o Ã© gerenciada via `Makefile` para simplificar as operaÃ§Ãµes mais comuns.

| Comando | DescriÃ§Ã£o |
|---|---|
| `make help` | Lista todos os comandos disponÃ­veis no Makefile. |
| `make up` | Inicia todos os serviÃ§os em modo detached (`docker compose up -d`). |
| `make down` | Para todos os serviÃ§os (`docker compose down`). |
| `make pull` | Baixa os modelos LLM definidos no arquivo `.env`. |
| `make ingest` | Processa e indexa os documentos da pasta `data/docs` no `pgvector`. |
| `make logs` | Mostra os logs de todos os serviÃ§os em tempo real. |
| `make logs-api`| Mostra os logs especÃ­ficos da API FastAPI. |
| `make status` | Exibe o status atual dos containers Docker. |
| `make reset` | **(CUIDADO)** Para os serviÃ§os e remove os volumes, incluindo a base vetorial. |

---

### ğŸ”§ ConfiguraÃ§Ã£o
A configuraÃ§Ã£o principal Ã© feita atravÃ©s do arquivo `.env`.

| VariÃ¡vel | DescriÃ§Ã£o | Exemplo |
|---|---|---|
| `OPENWEBUI_PORT` | Porta para a interface web. | `3000` |
| `API_PORT` | Porta para a API FastAPI. | `8000` |
| `SMALL_MODEL` | Modelo leve para tarefas rÃ¡pidas (agente Reflexivo). | `phi3:3.8b` |
| `GENERAL_MODEL`| Modelo geral para desenvolvimento (agente Dev). | `qwen2.5:7b` |
| `HEAVY_MODEL` | Modelo pesado para tarefas complexas (uso futuro). | `llama3.1:8b-instruct` |
| `POSTGRES_USER` | UsuÃ¡rio do banco de dados. | `sincerta` |
| `POSTGRES_PASSWORD`| Senha do banco de dados. | `escrita_segura_2024` |
| `POSTGRES_DB` | Nome do banco de dados. | `sincerta_memory` |
| `RAG_TOP_K` | NÃºmero de documentos relevantes a retornar na busca vetorial. | `5` |
| `RAG_CHUNK_SIZE`| Tamanho dos pedaÃ§os de texto ao dividir documentos. | `1000` |
| `EMBEDDING_MODEL`| Modelo de embedding para o RAG. | `bge-m3` |

---

### ğŸ“š Sistema RAG (Retrieval-Augmented Generation)
**Como Funciona**
1.  **IngestÃ£o**: Documentos da pasta `data/docs` sÃ£o divididos em pedaÃ§os (`chunks`), transformados em vetores (`embeddings`) e armazenados no `pgvector`.
2.  **Busca**: Uma pergunta do usuÃ¡rio Ã© convertida em um vetor e usada para encontrar os `chunks` mais relevantes no banco de dados.
3.  **Resposta**: O LLM recebe a pergunta original junto com o contexto dos `chunks` encontrados para formular uma resposta enriquecida.

**Tipos de Arquivo Suportados**
- ğŸ“„ Markdown (`.md`)
- ğŸ“ Texto (`.txt`)

**Uso do RAG**
```bash
# 1. Adicione seus documentos na pasta data/docs
cp meus-documentos/* data/docs/

# 2. Execute o comando de ingestÃ£o
make ingest
```
ApÃ³s a ingestÃ£o, os agentes usarÃ£o automaticamente o conhecimento dos seus documentos ao responder perguntas.

---

### ğŸ”Œ API Endpoints Principais
| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|---|---|---|
| `GET` | `/health` | Verifica a saÃºde da API. |
| `GET` | `/models` | Lista os modelos disponÃ­veis no Ollama. |
| `GET` | `/agents` | Lista os agentes ativos na API. |
| `POST`| `/chat` | Ponto central para interagir com os agentes. |
| `POST`| `/ingest`| Inicia o processo de ingestÃ£o de documentos. |
| `POST`| `/upload`| Permite o upload de arquivos para a pasta `data/docs`. |

---

### ğŸ¨ Manifesto "Escrita Sincerta"
**PrincÃ­pios Core**
- âœ… **Verdade > Agradar**: Se nÃ£o souber, admita e proponha uma soluÃ§Ã£o.
- âš¡ **DireÃ§Ã£o > DivagaÃ§Ã£o**: Resolva antes de pedir mais dados.
- ğŸ¯ **Clareza + Empatia**: Seja tÃ©cnico, mas humano e direto.

**Formato ObrigatÃ³rio de Resposta**
> ğŸ” **CONTEXTO**
> _[Problema identificado, situaÃ§Ã£o atual]_
>
> âš¡ **SOLUÃ‡ÃƒO**
> _[Abordagem tÃ©cnica, decisÃµes justificadas]_
>
> ğŸ’» **CÃ“DIGO/EXEMPLO**
> _[ImplementaÃ§Ã£o funcional, pronta para produÃ§Ã£o]_
>
> âœ… **CHECKLIST**
> _[CritÃ©rios de validaÃ§Ã£o, passos de teste]_

---

### ğŸ› ï¸ Desenvolvimento
**Estrutura do Projeto**
```
escrita-sincerta-llm/
 â”œâ”€ .env.example
 â”œâ”€ docker-compose.yml
 â”œâ”€ Makefile
 â”œâ”€ README.md
 â”œâ”€ data/
 â”‚   â”œâ”€ docs/              # PDFs, TXTs, MDs para ingestÃ£o RAG
 â”‚   â””â”€ vectors/           # Volume do pgvector
 â”œâ”€ api/
 â”‚   â”œâ”€ app.py             # FastAPI + endpoints principais
 â”‚   â”œâ”€ agents/
 â”‚   â”‚   â”œâ”€ base.py
 â”‚   â”‚   â”œâ”€ dev_fullstack.py
 â”‚   â”‚   â””â”€ reflexivo.py
 â”‚   â”œâ”€ tools/
 â”‚   â”‚   â”œâ”€ files.py
 â”‚   â”‚   â”œâ”€ rag.py
 â”‚   â”‚   â””â”€ sysinfo.py
 â”‚   â”œâ”€ prompts/
 â”‚   â”‚   â”œâ”€ manifesto_sincerta.md
 â”‚   â”‚   â”œâ”€ system_base.md
 â”‚   â”‚   â””â”€ styles.json
 â”‚   â””â”€ settings.py
 â””â”€ scripts/
     â”œâ”€ pull-models.sh
     â”œâ”€ dev.ps1
     â””â”€ dev.sh
```

---

### ğŸš¨ Troubleshooting
| Problema | DiagnÃ³stico | SoluÃ§Ã£o |
|---|---|---|
| **UI sem resposta** | O serviÃ§o do Ollama pode estar inativo. | Verifique o status com `make status` e os logs com `make logs`. Teste o Ollama diretamente: `curl http://localhost:11434/api/tags`. |
| **Modelo falha ao carregar** | MemÃ³ria insuficiente ou modelo corrompido. | Revise os logs do Ollama. Tente baixar o modelo novamente (`make pull`). |
| **Erro 500 na API** | Erro interno na aplicaÃ§Ã£o FastAPI. | Verifique os logs da API com `make logs-api` para identificar a causa. |
| **RAG nÃ£o encontra info** | ExtensÃ£o `pgvector` nÃ£o iniciou ou a ingestÃ£o falhou. | Verifique os logs do `postgres` e da `api`. Execute `make ingest` novamente. |

---

### ğŸ”® Roadmap e Status
- **Status Atual**: Em desenvolvimento.
- **PrÃ³ximas Funcionalidades**:
  1. Conectar embeddings locais (`bge-m3` via Ollama) para similaridade real no `rag.py`.
  2. Criar ferramentas adicionais: leitor de PDF/HTML, executor seguro de cÃ³digo.
  3. Registrar histÃ³rico de conversas no Postgres.
  4. Adicionar painel de mÃ©tricas (latÃªncia, tokens, modelo ativo).

---

### ğŸ“œ LicenÃ§a
Este projeto Ã© distribuÃ­do sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

### ğŸ¤ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir uma *issue* ou enviar um *pull request*.

---
*Desenvolvido com o Manifesto "Escrita Sincerta"*