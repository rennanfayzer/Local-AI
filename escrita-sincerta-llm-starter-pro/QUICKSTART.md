# âš¡ QUICK START - Escrita Sincerta LLM Pro
# âš¡ QUICK START - Escrita Sincerta LLM Pro (ExecuÃ§Ã£o Local)

## ğŸ¯ O QUE Ã‰?

Sistema LLM 100% local com **5 agentes especializados**, **roteamento inteligente** e **histÃ³rico de conversas persistente**.

**VersÃ£o**: 2.0.2 | **Status**: 70% âœ…

---

## ğŸš€ INSTALAÃ‡ÃƒO RÃPIDA

### PrÃ©-requisitos
- **Python 3.11+**
- **Ollama** instalado e rodando.

### Windows (PowerShell) - Recomendado
```powershell
# 1. Iniciar a API (Backend)
cd escrita-sincerta-llm-starter-pro
.\\run_local.ps1

# 2. Em um NOVO terminal, iniciar a Interface (Frontend)
cd escrita-sincerta-llm-starter-pro\\frontend
python -m http.server 3000
```

### Linux/macOS (ou Manual no Windows)
```bash
# 1. Crie e ative um ambiente virtual
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# .\\venv\\Scripts\\Activate.ps1 # Windows

# 2. Instale as dependÃªncias
pip install -r api/requirements.txt

# 3. Baixe os modelos LLM (se ainda nÃ£o tiver)
./scripts/pull-models.sh

# 4. Inicie a API
cd api
uvicorn app:app --reload

# 5. Em um NOVO terminal, inicie o Frontend
cd frontend
python3 -m http.server 3000
```

---

## ğŸŒ ACESSOS

- **Interface Web**: http://localhost:3000
- **API**: http://localhost:8000
- **DocumentaÃ§Ã£o**: http://localhost:8000/docs

---

## ğŸ¤– AGENTES DISPONÃVEIS

### 1. **Ideator** ğŸ’¡
**Uso**: IdeaÃ§Ã£o de SaaS, anÃ¡lise de mercado, MVPs  
**Modelo**: qwen2.5:7b  
**Exemplo**:
```json
POST /chat
{
  "agent": "ideator",
  "message": "Preciso de uma ideia inovadora para SaaS de gestÃ£o"
}
```

### 2. **Architect** ğŸ—ï¸
**Uso**: Arquitetura de sistemas, tech stack  
**Modelo**: llama3.1:8b-instruct  
**Exemplo**:
```json
POST /chat
{
  "agent": "architect",
  "message": "Design uma arquitetura para e-commerce escalÃ¡vel"
}
```

### 3. **Builder** ğŸ› ï¸
**Uso**: Scaffolding de projetos (React, FastAPI, Flutter...)  
**Modelo**: codegemma:7b  
**Exemplo**:
```json
POST /chat
{
  "agent": "builder",
  "message": "Crie um projeto React com TypeScript"
}
```

### 4. **DevFullstack** ğŸ’»
**Uso**: Desenvolvimento geral, cÃ³digo, debug  
**Modelo**: qwen2.5:7b  
**Exemplo**:
```json
POST /chat
{
  "agent": "dev_fullstack",
  "message": "Crie uma API REST com autenticaÃ§Ã£o JWT"
}
```

### 5. **Reflexivo** ğŸ§ 
**Uso**: AnÃ¡lise, planejamento, otimizaÃ§Ã£o  
**Modelo**: phi3:3.8b  
**Exemplo**:
```json
POST /chat
{
  "agent": "reflexivo",
  "message": "Analise os prÃ³s e contras de microservices"
}
```

---

## ğŸ§  ROTEAMENTO AUTOMÃTICO

**O sistema escolhe o modelo automaticamente** baseado em:
- Complexidade da tarefa
- Tipo de tarefa
- Performance histÃ³rica

**Endpoints:**
- `GET /routing/stats` - EstatÃ­sticas
- `POST /routing/test` - Testar roteamento
- `GET /routing/examples` - Ver exemplos

---

## ğŸ’¾ GERENCIAMENTO DE HISTÃ“RICO

**O sistema agora salva suas conversas no servidor.**

**Endpoints:**
- `GET /projects` - Lista seus projetos de conversa
- `POST /projects` - Cria um novo projeto
- `GET /history/{project_name}` - Carrega o histÃ³rico de um projeto

---

## ğŸ“Š RECURSOS IMPLEMENTADOS

âœ… **Infraestrutura Local** (100%)
- ExecuÃ§Ã£o nativa com Python venv
- FastAPI + Ollama
- ChromaDB para RAG
- PersistÃªncia de histÃ³rico em arquivos

âœ… **Agentes** (100%)
- 5 agentes especializados
- Sistema de roteamento inteligente

âœ… **RAG** (100%)
- IngestÃ£o de documentos
- Busca semÃ¢ntica
- Embeddings vetoriais

âœ… **API** (100%)
- 20+ endpoints funcionais
- Health checks
- DocumentaÃ§Ã£o automÃ¡tica

---

## ğŸš§ PRÃ“XIMAS FEATURES

ğŸ”² **Conversa por Voz** (Whisper + TTS)  
ğŸ”² **GeraÃ§Ã£o Visual** (Stable Diffusion)  
ğŸ”² **Templates Expandidos**  
ğŸ”² **Monitoramento AvanÃ§ado**  
ğŸ”² **Deploy em Cloud**  

---

## ğŸ› ï¸ COMANDOS ÃšTEIS

```powershell
# (No terminal da API) Para parar a API
Ctrl + C

# Verificar se o Ollama estÃ¡ rodando
curl http://localhost:11434

# Listar modelos baixados
ollama list
```

---

## ğŸ“š DOCUMENTAÃ‡ÃƒO

- **README Completo**: [README.md](README.md)
- **Roadmap Detalhado**: [ROADMAP.md](ROADMAP.md)
- **Status do Projeto**: [STATUS.md](STATUS.md)

---

## ğŸ†˜ TROUBLESHOOTING

### Problema: Modelos nÃ£o carregam
**SoluÃ§Ã£o**:
```powershell
# Windows
.\\scripts\\pull-modelsv.2.ps1

# Linux/macOS
./scripts/pull-models.sh
```

### Problema: API nÃ£o responde
**SoluÃ§Ã£o**:
- Verifique se o `run_local.ps1` (ou `uvicorn`) estÃ¡ em execuÃ§Ã£o sem erros.
- Certifique-se de que o Ollama estÃ¡ rodando.

### Problema: `ModuleNotFoundError`
**SoluÃ§Ã£o**:
- Certifique-se de que seu ambiente virtual estÃ¡ ativado.
- Rode `pip install -r api/requirements.txt` novamente.

---

## ğŸ’¡ EXEMPLOS DE USO

### IdeaÃ§Ã£o de SaaS
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "agent": "ideator",
    "message": "Gere uma ideia de SaaS para gestÃ£o de equipes remotas"
  }'
```

### Arquitetura
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "agent": "architect",
    "message": "Design uma arquitetura microservices para streaming"
  }'
```

### Scaffolding
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "agent": "builder",
    "message": "Crie um projeto FastAPI com PostgreSQL"
  }'
```

---

## ğŸ¯ PRÃ“XIMOS PASSOS

1. âœ… Baixe os modelos LLM (se necessÃ¡rio)
2. âœ… Inicie a API com `.\\run_local.ps1`
3. âœ… Inicie a interface com `python -m http.server 3000`
4. âœ… Acesse http://localhost:3000
5. âœ… Teste os agentes e o novo sistema de projetos
6. âœ… Explore a API em http://localhost:8000/docs

---

**ğŸš€ Desenvolvido com o Manifesto "Escrita Sincerta" - Direto, TÃ©cnico, Honesto.**
